{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/causal_inference.txt\", 'r') as f:\n",
    "    text = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for t in text:\n",
    "    res.append(list(map(int, t.strip('\\n').split(\" \")[:-1]))) # 最後空文字が入っている。\n",
    "#     print(t.strip('\\n').split(\" \")[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# コロンビア大学で用いられているサンプルデータセット\n",
    "http://www.cs.columbia.edu/~jebara/6998/hw2.pdf\n",
    "\n",
    "- the 1st column is the chosen arm\n",
    "- the 2nd column is binary reward \n",
    "- the remaining columns are the context features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.DataFrame(res)\n",
    "ds.columns = [\"arm\", \"reward\"] + [f\"feat_{i}\" for i in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ds.loc[:, \"feat_0\":].values\n",
    "y = ds.loc[:, \"reward\"].values\n",
    "arms = ds.loc[:,\"arm\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "sys.path.append(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.Arms import ContextualArms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools, os\n",
    "ds.groupby(\"arm\").mean()[\"reward\"].idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Arms = ContextualArms(n_action=10, max_n_sim=100, X=X, y=y,arms=arms, n_features=X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<src.Arms.ContextualArms at 0x113ee0950>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Arms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 100\n",
    "sigma=1; sigma_0=1\n",
    "A_inv =sigma_0/sigma * np.eye(d); A_inv\n",
    "b_t = np.zeros((d, 1))\n",
    "alpha = 0.05\n",
    "n_arms = 10\n",
    "n_sim = 1000\n",
    "history = dict(chosen_arms=[],rewards=[])\n",
    "mu_hat = np.zeros((n_arms, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Thompson sampling アルゴリズム\n",
    "for t in range(1, n_sim):\n",
    "    # 3. draw_theta\n",
    "    theta = np.random.multivariate_normal(A_inv@b_t.flatten(), sigma**2*A_inv, size=1)\n",
    "    # 4. A[t]はa_itの転置ver\n",
    "    # 各アームの特徴量を引く\n",
    "    # shape : (10, 100) 10 arms, (1, 100)の特徴量ベクトル\n",
    "    # 1次元目にアーム１から10までの特徴量を順番に格納している。\n",
    "    A_ = Arms.draw()\n",
    "    for i in range(n_arms):\n",
    "        mu_hat[i] = np.dot(A_[i].ravel(), theta.ravel())\n",
    "    i_star = mu_hat.argmax(0)[0]\n",
    "    history[\"chosen_arms\"].append(i_star)\n",
    "\n",
    "    #5. スコア最大の行動 i*　を選択して報酬を観測する。\n",
    "    reward = Arms.get_reward(index=i_star)\n",
    "    history[\"rewards\"].append(reward)\n",
    "    #6.  A-inverse/ bの更新をする。\n",
    "    a_is = A_[i_star, np.newaxis]\n",
    "    second_term = (A_inv@a_is.T@a_is@A_inv) / (1+a_is@A_inv@a_is.T)\n",
    "    A_inv = A_inv - second_term\n",
    "    b_t += a_is.T*reward    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  6,  0,  0,  0,  0,  0,\n",
       "         3,  5,  0,  0,  7,  7,  0,  0,  0,  0,  0, 23, 31,  0,  3,  4,\n",
       "         3,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 15, 39,  0,\n",
       "         0,  0,  9,  2,  1,  3,  0,  6,  0,  0,  0,  0,  0,  0,  1,  0,\n",
       "         0,  0,  0,  0,  0,  0,  1,  0,  0,  3,  7,  0,  0,  0,  0, 64,\n",
       "         5,  0,  0,  0,  0,  0,  6,  0,  3,  0,  1,  0,  0,  0, 13,  0,\n",
       "        24,  2,  0,  0]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_[1, np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logit Regression\n",
    "\n",
    "- logit モデルは対数事後確率の勾配ベクトルから陽に（解析的に）$\\theta$を求めることが難しい。\n",
    "\n",
    "$- \\log\\pi (\\theta| \\{i(s), X(s)\\}^t_{s=1})$\n",
    "$\\displaystyle = \\frac{\\theta^T \\theta}{2\\sigma^2_0} + \\sum^T_{s=1}log(1+\\exp(\\theta^Ta_{i(s), s})) - \\sum^T_{s:X(s)=1}\\theta^Ta_{i(s), s} + Constants. $\n",
    "\n",
    "\n",
    "$G_t(\\theta) = - \\nabla\\log\\pi (\\theta| \\{i(s), X(s)\\}^t_{s=1})$\n",
    "$\\displaystyle = \\frac{\\theta}{2\\sigma^2_0} + \\sum^t_{s=1}\\frac{e^{\\theta^Ta_{i(s), s}}a_{i(s), s}}{(1+\\exp(\\theta^Ta_{i(s), s}))} - \\sum^T_{s:X(s)=1}a_{i(s), s}$\n",
    "\n",
    "- $G_t(\\theta) = 0が\\theta$について解けない\n",
    "\n",
    "\n",
    "- そこで、数値計算をする。ニュートン法を用いて、負の対数事後確率を$\\hat{\\theta}_{MAP}$の周りで２次近似すると、($G_t(\\hat{\\theta_{MAP}}) = 0$より)\n",
    "\n",
    "- 負の対数事後確率が多変量正規分布の負の対数ゆうどに近似される。これをLaplas近似というらしい。\n",
    "    - $\\theta_{MAP} \\sim N(\\hat{\\theta_{MAP}}, H_t(\\hat{\\theta_{MAP}})^{-1})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def component_logit_hessian(theta, arm_feature):\n",
    "#     return np.exp(np.dot(theta.ravel(), arm_feature.ravel()))* arm_feature.T@arm_feature /(1+np.exp(np.dot(theta.ravel(), arm_feature.ravel())))**2\n",
    "def Hessian_inv(theta, Arms=None):\n",
    "    assert Arms is not None\n",
    "    print(theta.shape)\n",
    "    n_his = len(Arms.history_idx)\n",
    "    first_term = np.eye(d)/sigma_0\n",
    "    # self.cum_matrix\n",
    "    # initial: self.cum_matrix = np.zeros((d, d))\n",
    "    exp_theta_arm_feats = np.exp(X[Arms.history_idx]@theta.T)\n",
    "    print(exp_theta_arm_feats.shape)\n",
    "    sum_past_second_term = exp_theta_arm_feats.reshape((n_his, 1,1)) * (X[Arms.history_idx, :, np.newaxis]@X[Arms.history_idx, np.newaxis, :])\n",
    "    second_term = np.sum(sum_past_second_term, axis=0)# (100, 100)\n",
    "    hessian = first_term + second_term\n",
    "\n",
    "    return np.linalg.inv(hessian)\n",
    "\n",
    "def Gradient(theta, sigma_0,  Arms):\n",
    "    '''gradients vector for logit based posterior probability.'''\n",
    "    first_term = theta/sigma_0\n",
    "    exp_theta_arm_feats = np.exp(X[Arms.history_idx]@theta.T)\n",
    "    second_term = np.sum(exp_theta_arm_feats*X[Arms.history_idx]/(1+exp_theta_arm_feats), axis=0, keepdims=True) #1.\n",
    "    third_term = np.sum(X[Arms.history_idx][y[Arms.history_idx]==1], axis=0, keepdims=True).astype(np.float64)\n",
    "    # output shape (100, 1)\n",
    "    return (first_term + second_term - third_term).T\n",
    "\n",
    "\n",
    "def newton_iteration(theta, Arms, n_iteration=1000, thr=1e-10):\n",
    "    for _ in range(n_iteration):\n",
    "        H_inv = Hessian_inv(theta, Arms)\n",
    "        print(f\"iter_{_}:\", theta.shape)\n",
    "        theta_next = theta - (H_inv@Gradient(theta, sigma_0,  Arms)).ravel()\n",
    "        if np.sum((theta_next - theta)**2) < thr:\n",
    "            break\n",
    "        theta = theta_next\n",
    "        print(f\"iter_{_}:\", theta.shape)\n",
    "    return theta_next, H_inv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 100\n",
    "sigma=1; sigma_0=1\n",
    "A_inv =sigma_0/sigma * np.eye(d); A_inv\n",
    "b_t = np.zeros((d, 1))\n",
    "alpha = 0.05\n",
    "n_arms = 10\n",
    "n_sim = 1000\n",
    "history = dict(chosen_arms=[],rewards=[])\n",
    "mu_hat = np.zeros((n_arms, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 100)\n",
      "(999, 1)\n",
      "iter_0: (1, 100)\n",
      "iter_0: (1, 100)\n",
      "(1, 100)\n",
      "(999, 1)\n",
      "iter_1: (1, 100)\n",
      "iter_1: (1, 100)\n",
      "(1, 100)\n",
      "(999, 1)\n",
      "iter_2: (1, 100)\n",
      "iter_2: (1, 100)\n",
      "(1, 100)\n",
      "(999, 1)\n",
      "iter_3: (1, 100)\n",
      "iter_3: (1, 100)\n",
      "(1, 100)\n",
      "(999, 1)\n",
      "iter_4: (1, 100)\n",
      "iter_4: (1, 100)\n",
      "(1, 100)\n",
      "(999, 1)\n",
      "iter_5: (1, 100)\n",
      "iter_5: (1, 100)\n",
      "(1, 100)\n",
      "(999, 1)\n",
      "iter_6: (1, 100)\n",
      "iter_6: (1, 100)\n",
      "(1, 100)\n",
      "(999, 1)\n",
      "iter_7: (1, 100)\n",
      "iter_7: (1, 100)\n",
      "(1, 100)\n",
      "(999, 1)\n",
      "iter_8: (1, 100)\n",
      "iter_8: (1, 100)\n",
      "(1, 100)\n",
      "(999, 1)\n",
      "iter_9: (1, 100)\n",
      "iter_9: (1, 100)\n",
      "(1, 100)\n",
      "(999, 1)\n",
      "iter_10: (1, 100)\n",
      "iter_10: (1, 100)\n",
      "(1, 100)\n",
      "(999, 1)\n",
      "iter_11: (1, 100)\n",
      "iter_11: (1, 100)\n",
      "(1, 100)\n",
      "(999, 1)\n",
      "iter_12: (1, 100)\n",
      "iter_12: (1, 100)\n",
      "(1, 100)\n",
      "(999, 1)\n",
      "iter_13: (1, 100)\n",
      "iter_13: (1, 100)\n",
      "(1, 100)\n",
      "(999, 1)\n",
      "iter_14: (1, 100)\n",
      "iter_14: (1, 100)\n",
      "(1, 100)\n",
      "(999, 1)\n",
      "iter_15: (1, 100)\n",
      "iter_15: (1, 100)\n",
      "(1, 100)\n",
      "(999, 1)\n",
      "iter_16: (1, 100)\n",
      "iter_16: (1, 100)\n",
      "(1, 100)\n",
      "(999, 1)\n",
      "iter_17: (1, 100)\n",
      "iter_17: (1, 100)\n",
      "(1, 100)\n",
      "(999, 1)\n",
      "iter_18: (1, 100)\n",
      "iter_18: (1, 100)\n",
      "(1, 100)\n",
      "(999, 1)\n",
      "iter_19: (1, 100)\n",
      "iter_19: (1, 100)\n",
      "(1, 100)\n",
      "(999, 1)\n",
      "iter_20: (1, 100)\n",
      "iter_20: (1, 100)\n",
      "(1, 100)\n",
      "(999, 1)\n",
      "iter_21: (1, 100)\n",
      "iter_21: (1, 100)\n",
      "(1, 100)\n",
      "(999, 1)\n",
      "iter_22: (1, 100)\n",
      "iter_22: (1, 100)\n",
      "(1, 100)\n",
      "(999, 1)\n",
      "iter_23: (1, 100)\n",
      "iter_23: (1, 100)\n",
      "(1, 100)\n",
      "(999, 1)\n",
      "iter_24: (1, 100)\n",
      "iter_24: (1, 100)\n",
      "(1, 100)\n",
      "(999, 1)\n",
      "iter_25: (1, 100)\n",
      "iter_25: (1, 100)\n",
      "(1, 100)\n",
      "(999, 1)\n",
      "iter_26: (1, 100)\n",
      "iter_26: (1, 100)\n",
      "(1, 100)\n",
      "(999, 1)\n",
      "iter_27: (1, 100)\n",
      "iter_27: (1, 100)\n",
      "(1, 100)\n",
      "(999, 1)\n",
      "iter_28: (1, 100)\n",
      "iter_28: (1, 100)\n",
      "(1, 100)\n",
      "(999, 1)\n",
      "iter_29: (1, 100)\n",
      "iter_29: (1, 100)\n",
      "(1, 100)\n",
      "(999, 1)\n",
      "iter_30: (1, 100)\n",
      "iter_30: (1, 100)\n",
      "(1, 100)\n",
      "(999, 1)\n",
      "iter_31: (1, 100)\n",
      "iter_31: (1, 100)\n",
      "(1, 100)\n",
      "(999, 1)\n",
      "iter_32: (1, 100)\n",
      "iter_32: (1, 100)\n",
      "(1, 100)\n",
      "(999, 1)\n",
      "iter_33: (1, 100)\n",
      "iter_33: (1, 100)\n",
      "(1, 100)\n",
      "(999, 1)\n",
      "iter_34: (1, 100)\n",
      "iter_34: (1, 100)\n",
      "(1, 100)\n",
      "(999, 1)\n",
      "iter_35: (1, 100)\n",
      "iter_35: (1, 100)\n",
      "(1, 100)\n",
      "(999, 1)\n",
      "iter_36: (1, 100)\n",
      "iter_36: (1, 100)\n",
      "(1, 100)\n",
      "(999, 1)\n",
      "iter_37: (1, 100)\n",
      "iter_37: (1, 100)\n",
      "(1, 100)\n",
      "(999, 1)\n",
      "iter_38: (1, 100)\n",
      "iter_38: (1, 100)\n",
      "(1, 100)\n",
      "(999, 1)\n",
      "iter_39: (1, 100)\n",
      "iter_39: (1, 100)\n",
      "(1, 100)\n",
      "(999, 1)\n",
      "iter_40: (1, 100)\n",
      "iter_40: (1, 100)\n",
      "(1, 100)\n",
      "(999, 1)\n",
      "iter_41: (1, 100)\n",
      "iter_41: (1, 100)\n",
      "(1, 100)\n",
      "(999, 1)\n",
      "iter_42: (1, 100)\n",
      "iter_42: (1, 100)\n",
      "(1, 100)\n",
      "(999, 1)\n",
      "iter_43: (1, 100)\n",
      "iter_43: (1, 100)\n",
      "(1, 100)\n",
      "(999, 1)\n",
      "iter_44: (1, 100)\n",
      "iter_44: (1, 100)\n",
      "(1, 100)\n",
      "(999, 1)\n",
      "iter_45: (1, 100)\n",
      "iter_45: (1, 100)\n",
      "(1, 100)\n",
      "(999, 1)\n",
      "iter_46: (1, 100)\n",
      "iter_46: (1, 100)\n",
      "(1, 100)\n",
      "(999, 1)\n",
      "iter_47: (1, 100)\n",
      "iter_47: (1, 100)\n",
      "(1, 100)\n",
      "(999, 1)\n",
      "iter_48: (1, 100)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-c7d5be9ce398>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mmu_hat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta_tilde\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mi_star\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmu_hat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi_star\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "# ロジスティックモデル上のトンプソン抽出\n",
    "# WRITE CODE\n",
    "# Newton method\n",
    "theta, H_inv = newton_iteration(theta, Arms, n_iteration=1000, thr=1e-10)\n",
    "# 6. draw_theta\n",
    "theta_tilde = np.random.multivariate_normal(theta.ravel(), H_inv, size=1)\n",
    "# 各アームの特徴量を引く\n",
    "# shape : (10, 1, 100) 10 arms, (1, 100)の特徴量ベクトル\n",
    "# 1次元目にアーム１から10までの特徴量を順番に格納している。\n",
    "A_ = Arms.draw()\n",
    "for i in range(n_arms):\n",
    "    mu_hat[i] = np.dot(A_[i].ravel(), theta_tilde.ravel())\n",
    "i_star = mu_hat.argmax(0)[0]\n",
    "history[\"chosen_arms\"].append(i_star)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can implemented one step learning.\n",
    "Then \n",
    "\n",
    "## If n_sim is sufficiently small, then the draws of theta_tilde wont work because H_inv is not solved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "SVD did not converge",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-d62034f82f14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtheta_tilde\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultivariate_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH_inv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.multivariate_normal\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msvd\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.venv/lib/python3.7/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36msvd\u001b[0;34m(a, full_matrices, compute_uv, hermitian)\u001b[0m\n\u001b[1;32m   1634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1635\u001b[0m         \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'D->DdD'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'd->ddd'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1636\u001b[0;31m         \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgufunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1637\u001b[0m         \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1638\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_realType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venv/lib/python3.7/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36m_raise_linalgerror_svd_nonconvergence\u001b[0;34m(err, flag)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_svd_nonconvergence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SVD did not converge\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_lstsq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLinAlgError\u001b[0m: SVD did not converge"
     ]
    }
   ],
   "source": [
    "theta_tilde = np.random.multivariate_normal(theta.ravel(), H_inv, size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       ...,\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H_inv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \\exp(\\theta^T a_{i(s),s})\n",
    "exp_theta_arm_feats = np.exp(X[Arms.history_idx]@theta.T)\n",
    "second_term = np.sum(exp_theta_arm_feats*X[Arms.history_idx]/(1+exp_theta_arm_feats), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.22606446e-16],\n",
       "       [2.26175669e-01],\n",
       "       [6.66285331e+00],\n",
       "       [1.34520764e+00],\n",
       "       [5.72468099e-01],\n",
       "       [1.31072705e+00],\n",
       "       [2.54577232e-01],\n",
       "       [1.29484757e+00],\n",
       "       [8.84702170e-02],\n",
       "       [2.28285222e+03]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_theta_arm_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[66,  0,  0, 14,  0,  0,  0,  0,  0, 23,  0,  7, 19,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  3,  0,  0,  0,\n",
       "         0,  0,  7,  0,  4,  9,  0,  0,  0,  0,  0, 11,  4,  7,  0, 10,\n",
       "         0,  0,  0,  0,  0,  0,  0, 38,  0,  1, 12,  8,  0,  0,  0,  0,\n",
       "         0,  5,  0,  0,  2,  0,  0,  0, 14,  0,  0,  0,  0,  0,  3, 10,\n",
       "         2,  0,  0,  0,  1,  0,  0,  2,  0,  0,  0,  8,  0,  0,  1,  3,\n",
       "         6,  0,  0,  0]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[Arms.history_idx, np.newaxis,:][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hessianの要素を計算する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.sum(X[Arms.history_idx, :, np.newaxis]@X[Arms.history_idx, np.newaxis, :], axis=0)\n",
    "hoge = exp_theta_arm_feats.reshape(10, 1,1) * (X[Arms.history_idx, :, np.newaxis]@X[Arms.history_idx, np.newaxis, :])\n",
    "np.sum(hoge, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 100, 100)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X[Arms.history_idx, :, np.newaxis]@X[Arms.history_idx, np.newaxis, :]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 掛け算の動作確認\n",
    "# 各試行（n_sim）ごとに、(10, 1) × (1, 10)の掛け算がうまくできているか確認\n",
    "np.all(X[Arms.history_idx[0], np.newaxis].T@X[Arms.history_idx[0], np.newaxis] == (X[Arms.history_idx, :, np.newaxis]@X[Arms.history_idx, np.newaxis, :])[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 掛け算の動作確認\n",
    "# 各試行のnp.exp(X[Arms.history_idx]@theta.T)と上の行列がそれぞれ掛け合わせられてるか確認\n",
    "np.all(hoge[0] == exp_theta_arm_feats[0, 0] * (X[Arms.history_idx, :, np.newaxis]@X[Arms.history_idx, np.newaxis, :])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(hoge, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 100, 100)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X[Arms.history_idx, :, np.newaxis]@X[Arms.history_idx, np.newaxis, :]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 100, 100)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hoge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all((X[Arms.history_idx, :, np.newaxis]@X[Arms.history_idx, np.newaxis, :])[0] == X[Arms.history_idx[0], :, np.newaxis]@X[Arms.history_idx[0], np.newaxis, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4356,    0,    0, ...,    0,    0,    0],\n",
       "       [   0,    0,    0, ...,    0,    0,    0],\n",
       "       [   0,    0,    0, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,    0,    0,    0],\n",
       "       [   0,    0,    0, ...,    0,    0,    0],\n",
       "       [   0,    0,    0, ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[Arms.history_idx[0], :, np.newaxis]@X[Arms.history_idx[0], np.newaxis, :]\n",
    "# first_term = theta/sigma_0\n",
    "# exp_theta_arm_feats = np.exp(X[Arms.history_idx]@theta.T)\n",
    "# second_term = np.sum(exp_theta_arm_feats*X[Arms.history_idx]/(1+exp_theta_arm_feats), axis=0, keepdims=True) #1.\n",
    "# third_term = np.sum(X[Arms.history_idx][y[Arms.history_idx]==1], axis=0, keepdims=True).astype(np.float64)\n",
    "# first_term + second_term - third_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(exp_theta_arm_feats*X[Arms.history_idx])[2] == exp_theta_arm_feats[2] * X[Arms.history_idx][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.00050632e+03, 6.55363525e+00, 7.78987402e+04, 1.28421873e+02,\n",
       "       2.28344424e+04, 0.00000000e+00, 2.49038139e+01, 1.33257066e+01,\n",
       "       0.00000000e+00, 1.15041526e+04, 3.88149911e+04, 2.22655876e+00,\n",
       "       5.88031060e+01, 1.40247794e+02, 6.66285331e+00, 3.42495686e+04,\n",
       "       5.09154464e-01, 1.65345183e+01, 1.18737590e+02, 0.00000000e+00,\n",
       "       8.46030976e+04, 1.10153461e+01, 0.00000000e+00, 2.05610280e+01,\n",
       "       0.00000000e+00, 8.84406513e+01, 2.33146851e+03, 1.77921582e+01,\n",
       "       1.57403770e+01, 3.42470215e+04, 2.28310680e+03, 5.09154464e-01,\n",
       "       1.27288616e+00, 5.30821302e-01, 7.83649383e+00, 3.19645345e+04,\n",
       "       2.84978677e+01, 2.29830161e+03, 2.65410651e-01, 2.56022022e+03,\n",
       "       1.36999059e+04, 0.00000000e+00, 2.51997092e+01, 2.20390979e+01,\n",
       "       2.15688777e+01, 2.17146132e+02, 5.55484765e+01, 2.14604955e+01,\n",
       "       4.62589630e+03, 4.57027806e+03, 1.46277277e+01, 2.72598713e+01,\n",
       "       3.13060856e+00, 2.15160233e+01, 1.99885599e+01, 1.03793556e+02,\n",
       "       0.00000000e+00, 2.05485985e+04, 2.26399123e+01, 6.86637929e+03,\n",
       "       2.96802454e+04, 1.82672169e+04, 3.97625501e+00, 4.47289028e+00,\n",
       "       3.34453393e+02, 1.43277800e+01, 2.28379698e+04, 5.72468099e-01,\n",
       "       3.29529151e+01, 1.59873069e+04, 8.74811888e+00, 2.94879390e+01,\n",
       "       1.70873179e+01, 4.56863129e+03, 1.63389609e+02, 5.72468099e-01,\n",
       "       4.56890596e+03, 1.29484757e+00, 1.18749602e+05, 2.46897648e+01,\n",
       "       6.85115288e+03, 1.29484757e+00, 2.28307840e+03, 5.47929769e+04,\n",
       "       9.95633527e+00, 6.86269211e+01, 1.01830893e+00, 1.65541094e+01,\n",
       "       4.89832603e+00, 2.12328521e+00, 6.89668270e+00, 3.06261194e+00,\n",
       "       4.01224790e+01, 9.06393297e+00, 1.66352106e+01, 4.27992035e+01,\n",
       "       4.61889997e+03, 4.06975142e+01, 9.06393297e+00, 8.09214331e+01])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(exp_theta_arm_feats*X[Arms.history_idx], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exp_theta_arm_feats[2]\n",
    "(exp_theta_arm_feats*X[Arms.history_idx]/(1+exp_theta_arm_feats))[0] == (exp_theta_arm_feats*X[Arms.history_idx])[0]/(1+exp_theta_arm_feats)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([80.07902537,  2.83617888, 76.1638408 , 58.03467343, 13.3484506 ,\n",
       "        0.        , 10.77747973,  1.73900062,  0.        , 48.95679219,\n",
       "       22.26810465,  1.49800864, 27.85694738, 60.69422797,  0.86950031,\n",
       "       20.52711729,  0.40583748,  8.03292197, 17.2349045 ,  0.        ,\n",
       "       62.39529603,  5.51765069,  0.        ,  2.97255797,  0.        ,\n",
       "       22.35307394, 22.44831799,  8.26565787,  9.69090105, 18.51368676,\n",
       "        1.20248088,  0.40583748,  1.0145937 ,  0.48767646,  3.58974398,\n",
       "       17.23281046, 12.99101484,  8.65064007,  0.24383823, 39.839149  ,\n",
       "        8.32961103,  0.        ,  4.87145489, 11.19684101,  5.85367997,\n",
       "       32.85367713, 17.77229189,  9.99881743, 10.00908323,  4.07761416,\n",
       "        6.10405152,  4.00603761,  1.54030903,  3.82601337,  2.60850092,\n",
       "       47.35483004,  0.        , 10.86085101, 10.73329428,  9.31451931,\n",
       "       15.57669426, 10.60062894,  2.11065301,  2.05977525, 44.04225116,\n",
       "        6.60588943, 14.69022928,  0.36405705,  8.25390759,  8.41980382,\n",
       "        4.04568072, 14.35205368,  8.60485959,  3.9948327 , 23.18715473,\n",
       "        0.36405705,  3.64316965,  0.56424121, 68.664429  , 15.82027366,\n",
       "        4.48971052,  0.56424121,  1.18401831, 27.67861486,  5.99709217,\n",
       "       29.90478411,  0.81167496,  3.24389197,  2.87859987,  1.95070584,\n",
       "        3.12037703,  1.66576968,  7.38659916,  3.94968847,  4.37694425,\n",
       "        9.01669117, 28.01810916, 18.55525949,  3.94968847, 16.89828061])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Regrets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 関数にするかも\n",
    "class RegretCalculator():\n",
    "    '\"EnvとAgentのヒストリーを踏まえて、期待リグレットを計算する。\"'\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
